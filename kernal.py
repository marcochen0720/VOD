# -*- coding: utf-8 -*-
"""
VODï¼šæ ¸ K çš„å‡¹æ€§ä¸äºŒå…ƒä¿¡å·çš„ä¿¡æ¯æ”¹è¿›ï¼ˆæœ€ç»ˆç‰ˆï¼Œå« K åˆ¤åˆ«ä¸ tau é˜²å‘†ï¼‰
- å…ˆéªŒï¼šæˆªæ–­æ³Šæ¾ï¼ˆÎ¸>=1ï¼‰ï¼Œåœ¨ {1,...,n_max} ä¸Šå½’ä¸€åŒ–
- å‡è¡¡ï¼šÎ£ Î¼(Î¸)(1-p)^(Î¸-1) = c/Rï¼›è¾¹ç•Œ Î¼(1)â‰¥c/R => p*=1
- å±€éƒ¨éå‡¹æ€§ï¼ˆJensenï¼‰ï¼šå¯¹ç§°æ¬è¿ Îµ è´¨é‡åš Jensen æ£€éªŒ
- è§£æåˆ¤åˆ«æ ¸ Kï¼šK = (B/Gp) Î”Ï•' - 2 Î”v'ï¼Œç›¸é‚»/å…¨å¯¹æ‰«æ
- å…¨å±€äºŒå…ƒä¿¡å·ï¼šé˜ˆå€¼æ‰«æï¼Œä¸¥æ ¼è®¡ç®— Ï„_L, Ï„_Hï¼Œæ–­è¨€ Ï„_L+Ï„_H=1
- è¾“å‡ºï¼šå›¾ + Excelï¼ˆå«æ¯ä¸ª Î» çš„é˜ˆå€¼æ‰«æè¡¨ä¸æ ¸è¡¨ï¼‰
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import brentq, minimize_scalar
from scipy.special import factorial
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')

# --------- ä¸­æ–‡å­—ä½“ ---------
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'STHeiti']
plt.rcParams['axes.unicode_minus'] = False


class VODKernelBinaryAnalyzer:
    def __init__(self, n_max=30, R=10.0, c=1.0, V=50.0):
        self.n_max = int(n_max)
        self.R = float(R)
        self.c = float(c)
        self.V = float(V)
        self.states = np.arange(1, self.n_max + 1, dtype=int)

    # ------------------ å…ˆéªŒï¼ˆæˆªæ–­æ³Šæ¾å¹¶å½’ä¸€åŒ–ï¼‰ ------------------
    def prior_poisson_trunc(self, lam: float) -> np.ndarray:
        # pmf for Î¸=1..n_max
        raw = np.array([lam**k * np.exp(-lam) / factorial(k) for k in self.states], dtype=float)
        # æ¡ä»¶åŒ–ï¼šå»é™¤ Î¸=0 çš„æ¦‚ç‡ï¼Œå†åœ¨ {1..n_max} ä¸Šå½’ä¸€åŒ–
        denom = 1.0 - np.exp(-lam)
        raw = raw / denom
        prior = raw / raw.sum()
        # é˜²å‘†
        prior = np.maximum(prior, 0.0)
        prior = prior / prior.sum()
        return prior

    # ------------------ å‡è¡¡ p(Î¼) ------------------
    def equilibrium_p(self, posterior: np.ndarray) -> float:
        target = self.c / self.R
        mu1 = float(posterior[0])  # Î¼(1)
        # è¾¹ç•Œï¼šF(1-)=Î¼(1)-c/R
        if mu1 >= target - 1e-12:
            return 1.0

        def F(p):
            if p <= 0.0 or p >= 1.0:
                return np.inf
            lhs = np.sum(posterior * (1.0 - p) ** (self.states - 1))
            return lhs - target

        try:
            return brentq(F, 1e-8, 1.0 - 1e-8)
        except ValueError:
            # ç†è®ºä¸Šä¸ä¼šè§¦å‘ï¼›ä½œä¸ºå…œåº•
            def sq(p):
                if p <= 0.0 or p >= 1.0:
                    return 1e9
                return (F(p)) ** 2
            res = minimize_scalar(sq, bounds=(1e-6, 1.0 - 1e-6), method='bounded')
            if res.success:
                return float(np.clip(res.x, 1e-6, 1.0 - 1e-6))
            # æœ€åå…œåº•ï¼šè¿”å›ä¸€ä¸ªä¿å®ˆçš„å†…ç‚¹
            return 0.5

    # ------------------ ç¦åˆ© v(Î¼) ------------------
    def welfare(self, posterior: np.ndarray):
        p = self.equilibrium_p(posterior)
        theta = self.states.astype(float)
        # ç”Ÿå‘½æˆåŠŸæ¦‚ç‡
        success = 1.0 - (1.0 - p) ** theta
        # å”¯ä¸€å“åº”æœŸæœ›
        unique = theta * p * (1.0 - p) ** (theta - 1.0)
        # æ€»å“åº”
        total = theta * p
        v = float(np.dot(posterior, self.V * success + self.R * unique - self.c * total))
        return v, p

    # ------------------ Jensen å±€éƒ¨å‡¹æ€§ï¼ˆå¯¹ç§°æ¬è¿ï¼‰ ------------------
    def local_concavity_kernel(self, prior: np.ndarray, eps=1e-3, n_pairs=60, rng_seed=12345):
        v0, p0 = self.welfare(prior)
        n = len(prior)

        # å€™é€‰å¯¹ï¼ˆä¸¤è¾¹éƒ½æœ‰ä½™é‡ â‰¥ epsï¼‰
        candidates = [(i, j) for i in range(n) for j in range(n)
                      if i != j and prior[i] >= eps and prior[j] >= eps]
        if not candidates:
            return dict(is_locally_concave=True, n_pairs_tested=0, n_viol=0,
                        max_gap=0.0, v0=v0, p0=p0)

        rng = np.random.default_rng(rng_seed)
        idxs = rng.choice(len(candidates), size=min(n_pairs, len(candidates)), replace=False)

        viol_gaps = []
        tested = 0
        for k in idxs:
            i, j = candidates[k]
            mu_plus = prior.copy()
            mu_minus = prior.copy()
            # i->j ä¸ j->i å¯¹ç§°è½¬ç§» eps
            mu_plus[i] -= eps; mu_plus[j] += eps
            mu_minus[j] -= eps; mu_minus[i] += eps
            # ç®€å•æ£€æŸ¥
            if (mu_plus < -1e-12).any() or (mu_minus < -1e-12).any():
                continue
            # ç²¾åº¦ä¿®æ­£
            mu_plus = np.maximum(mu_plus, 0.0); mu_plus /= mu_plus.sum()
            mu_minus = np.maximum(mu_minus, 0.0); mu_minus /= mu_minus.sum()

            v_plus, _ = self.welfare(mu_plus)
            v_minus, _ = self.welfare(mu_minus)
            gap = 0.5 * (v_plus + v_minus) - v0  # å‡¹å‡½æ•°åº” â‰¤ 0
            if gap > 1e-10:
                viol_gaps.append(gap)
            tested += 1

        return dict(is_locally_concave=(len(viol_gaps) == 0),
                    n_pairs_tested=tested,
                    n_viol=len(viol_gaps),
                    max_gap=(max(viol_gaps) if viol_gaps else 0.0),
                    v0=v0, p0=p0)

    # ================== è§£æåˆ¤åˆ«æ‰€éœ€çš„å¯¼æ•° & æ ¸ K ==================
    def _phi_prime(self, theta: float, p: float) -> float:
        return -(theta - 1.0) * (1.0 - p) ** (theta - 2.0)

    def _vtheta_prime(self, theta: float, p: float) -> float:
        # ä¸è¯æ˜ä¸€è‡´ï¼šv_theta'(p)
        return (
            self.V * theta * (1.0 - p) ** (theta - 1.0)
            + self.R * (theta * (1.0 - p) ** (theta - 1.0)
                        - theta * (theta - 1.0) * p * (1.0 - p) ** (theta - 2.0))
            - self.c * theta
        )

    def _Bgp_at(self, mu: np.ndarray, p: float):
        theta = self.states.astype(float)
        v1 = np.array([self._vtheta_prime(t, p) for t in theta], dtype=float)
        phi1 = np.array([self._phi_prime(t, p) for t in theta], dtype=float)
        B = float(np.dot(mu, v1))
        Gp = float(np.dot(mu, phi1))  # å†…ç‚¹ä¸‹ < 0
        return B, Gp, v1, phi1

    def kernel_K(self, mu: np.ndarray, theta_L: int, theta_H: int):
        """
        æŒ‰è§£æåˆ¤åˆ«ï¼šK = (B/Gp) * Î”Ï•' - 2 * Î”v'ã€‚
        è¿”å› K åŠç»„æˆéƒ¨ä»¶ï¼Œä¾›è°ƒè¯•æˆ–å¯¼å‡ºã€‚
        """
        v0, p = self.welfare(mu)               # ç»Ÿä¸€ä½¿ç”¨ p^*(mu)
        B, Gp, v1, phi1 = self._Bgp_at(mu, p)
        dphi1 = phi1[theta_H - 1] - phi1[theta_L - 1]
        dv1   = v1[theta_H - 1] - v1[theta_L - 1]
        K = (B / Gp) * dphi1 - 2.0 * dv1
        return dict(K=K, B=B, Gp=Gp, dphi1=dphi1, dv1=dv1, p=p, v0=v0)

    def scan_kernel(self, mu: np.ndarray, neighbours_only: bool = True) -> pd.DataFrame:
        """
        æ‰«ææ ¸ Kï¼šé»˜è®¤ä»…æ‰«æç›¸é‚»å¯¹ (k, k+1)ï¼Œæ›´ç¨³å¥ï¼›ä¹Ÿå¯æ‰«ææ‰€æœ‰æˆå¯¹ã€‚
        """
        pairs = []
        if neighbours_only:
            for t in range(1, self.n_max):
                pairs.append((t, t + 1))
        else:
            for i in range(1, self.n_max):
                for j in range(i + 1, self.n_max + 1):
                    pairs.append((i, j))
        rows = []
        for (L, H) in pairs:
            rows.append(dict(theta_L=L, theta_H=H, **self.kernel_K(mu, L, H)))
        df = pd.DataFrame(rows)
        df['K_positive'] = df['K'] > 0
        return df

    # ------------------ äºŒå…ƒä¿¡å·ï¼šä¸¥æ ¼çš„ Ï„ ä¸åéªŒ ------------------
    def binary_split_result(self, prior: np.ndarray, theta_star: int):
        """
        ä½å—ï¼š{1,...,Î¸*-1} ï¼›é«˜å—ï¼š{Î¸*,...,n_max}
        ç¨³å¥è®¡ç®— tau_L, tau_Hï¼Œå¹¶å¯¹ posterior è¿›è¡Œå®‰å…¨å½’ä¸€åŒ–ã€‚
        """
        prior = prior / prior.sum()
        idx = int(np.clip(theta_star, 1, self.n_max))

        # --- ç¨³å¥çš„å—æ¦‚ç‡ ---
        tau_L_raw = float(prior[:idx - 1].sum()) if idx > 1 else 0.0
        tau_L = 0.0 if tau_L_raw < 1e-15 else tau_L_raw
        tau_H = 1.0 - tau_L
        if tau_H < 1e-15:    # æç«¯æƒ…å½¢ï¼šå³å—å‡ ä¹ç©º
            tau_H = 0.0
            tau_L = 1.0

        # --- æ„é€ åéªŒ ---
        post_L = np.zeros_like(prior)
        post_H = np.zeros_like(prior)
        if tau_L > 0.0 and idx > 1:
            post_L[:idx - 1] = prior[:idx - 1] / tau_L
        if tau_H > 0.0:
            post_H[idx - 1:] = prior[idx - 1:] / tau_H

        # --- å®‰å…¨å½’ä¸€åŒ–ï¼ˆé˜²æ•°å€¼æ¼‚ç§»ï¼‰---
        if tau_L > 0.0:
            sL = post_L.sum()
            if not np.isfinite(sL) or sL <= 0:
                block = prior[:idx - 1]
                s = block.sum()
                post_L = np.zeros_like(prior)
                if s > 0:
                    post_L[:idx - 1] = block / s
            else:
                post_L /= sL

        if tau_H > 0.0:
            sH = post_H.sum()
            if not np.isfinite(sH) or sH <= 0:
                block = prior[idx - 1:]
                s = block.sum()
                post_H = np.zeros_like(prior)
                if s > 0:
                    post_H[idx - 1:] = block / s
            else:
                post_H /= sH

        # --- è®¡ç®—ç¦åˆ© ---
        vL, pL = (np.nan, np.nan)
        if tau_L > 0.0:
            vL, pL = self.welfare(post_L)

        vH, pH = (np.nan, np.nan)
        if tau_H > 0.0:
            vH, pH = self.welfare(post_H)

        EV = (tau_L * (0.0 if np.isnan(vL) else vL) +
              tau_H * (0.0 if np.isnan(vH) else vH))

        return dict(
            threshold=idx,
            tau_L=float(tau_L), tau_H=float(tau_H),
            vL=float(vL) if not np.isnan(vL) else np.nan,
            vH=float(vH) if not np.isnan(vH) else np.nan,
            EV=float(EV),
            pL=float(pL) if not np.isnan(pL) else np.nan,
            pH=float(pH) if not np.isnan(pH) else np.nan
        )

    def best_binary_improvement(self, prior: np.ndarray):
        v0, p0 = self.welfare(prior)
        best = None
        per_threshold = []

        for th in range(1, self.n_max + 1):
            res = self.binary_split_result(prior, th)
            res['improvement'] = res['EV'] - v0
            res['improvement_pct'] = 100.0 * (res['improvement'] / abs(v0) if v0 != 0 else 0.0)
            per_threshold.append(res)
            if (best is None) or (res['improvement'] > best['improvement']):
                best = res

        best['v0'] = v0
        best['p0'] = p0
        return best, per_threshold

    # ------------------ ä¸»å…¥å£ï¼šæ‰«æ Î» å¹¶è¾“å‡º ------------------
    def run(self, lam_values, outdir="results_kernel_binary_Kfinal", scan_all_pairs=False):
        os.makedirs(outdir, exist_ok=True)
        rows = []
        per_lambda_thr_tables = {}
        per_lambda_K_tables = {}

        print(f"å‚æ•°ï¼šR={self.R:.1f}, c={self.c:.1f}, V={self.V:.1f}ï¼Œc/R={self.c/self.R:.3f}")
        print("-" * 66)

        for lam in lam_values:
            prior = self.prior_poisson_trunc(lam)

            # å±€éƒ¨å‡¹æ€§ï¼ˆJensenï¼‰
            loc = self.local_concavity_kernel(prior, eps=1e-3, n_pairs=80)

            # è§£ææ ¸ Kï¼ˆç›¸é‚»å¯¹/å…¨å¯¹ï¼‰
            ker = self.scan_kernel(prior, neighbours_only=not scan_all_pairs)
            any_K_pos = bool(ker['K_positive'].any())
            K_pos_pairs = int(ker['K_positive'].sum())

            # äºŒå…ƒä¿¡å·
            best, thr_table = self.best_binary_improvement(prior)

            rows.append(dict(
                lam=lam,
                welfare_prior=loc['v0'],
                p_prior=loc['p0'],
                locally_concave=loc['is_locally_concave'],
                max_jensen_gap=loc['max_gap'],
                best_threshold=best['threshold'],
                tau_L=best['tau_L'], tau_H=best['tau_H'],
                vL=best['vL'], vH=best['vH'],
                EV=best['EV'],
                improvement=best['improvement'],
                improvement_pct=best['improvement_pct'],
                any_K_pos=any_K_pos,
                K_pos_pairs=K_pos_pairs
            ))
            per_lambda_thr_tables[lam] = pd.DataFrame(thr_table)
            per_lambda_K_tables[lam] = ker

            tag = "å‡¹" if loc['is_locally_concave'] else "éå‡¹"
            print(f"Î»={lam:.1f}: {tag}ï¼Œæ”¹è¿› {best['improvement_pct']:.2f}% ï¼ŒÎ¸*={best['threshold']}, "
                  f"Ï„_L={best['tau_L']:.3f}, Ï„_H={best['tau_H']:.3f} | æ ¸>0 å¯¹æ•°={K_pos_pairs}")

        df_main = pd.DataFrame(rows)

        # ====== ç”»å›¾ ======
        fig, axes = plt.subplots(3, 3, figsize=(16, 12))

        ax = axes[0, 0]
        colors = ['green' if b else 'red' for b in df_main['locally_concave']]
        ax.scatter(df_main['lam'], df_main['welfare_prior'], c=colors, s=50, alpha=0.8)
        ax.set_title('å±€éƒ¨å‡¹æ€§ï¼ˆç»¿=å‡¹ï¼Œçº¢=éå‡¹ï¼‰'); ax.set_xlabel('Î»'); ax.set_ylabel('æ— ä¿¡å·ç¦åˆ© v(Î¼)'); ax.grid(alpha=0.3)

        ax = axes[0, 1]
        corner_mask = (df_main['p_prior'] > 0.999)
        ax.scatter(df_main[~corner_mask]['lam'], df_main[~corner_mask]['p_prior'],
                   c='tab:blue', label='å†…ç‚¹', s=50)
        ax.scatter(df_main[corner_mask]['lam'], df_main[corner_mask]['p_prior'],
                   c='tab:red', label='è§’ç‚¹(p=1)', s=50)
        ax.set_title('å‡è¡¡ç±»å‹'); ax.set_xlabel('Î»'); ax.set_ylabel('å‡è¡¡å“åº”ç‡ p'); ax.legend(); ax.grid(alpha=0.3)

        ax = axes[0, 2]
        mu1 = [self.prior_poisson_trunc(l)[0] for l in df_main['lam']]
        ax.plot(df_main['lam'], mu1, label='Î¼(1)')
        ax.axhline(y=self.c/self.R, color='r', ls='--', label=f'c/R={self.c/self.R:.3f}')
        ax.set_title('Î¼(1) ä¸ c/R'); ax.set_xlabel('Î»'); ax.set_ylabel('æ¦‚ç‡'); ax.legend(); ax.grid(alpha=0.3)

        ax = axes[1, 0]
        ax.plot(df_main['lam'], df_main['improvement_pct'], 'o-', color='tab:green')
        ax.axhline(0, color='k', ls='--', alpha=0.4)
        ax.set_title('æœ€ä¼˜äºŒå…ƒæ”¹è¿›ï¼ˆ%ï¼‰'); ax.set_xlabel('Î»'); ax.set_ylabel('æ”¹è¿›ç™¾åˆ†æ¯”'); ax.grid(alpha=0.3)

        ax = axes[1, 1]
        ax.plot(df_main['lam'], df_main['max_jensen_gap'], 'o-', color='tab:orange')
        ax.set_title('Jensen æœ€å¤§è¿èƒŒï¼ˆéå‡¹åº¦é‡ï¼‰'); ax.set_xlabel('Î»'); ax.set_ylabel('max gap'); ax.grid(alpha=0.3)

        ax = axes[1, 2]
        ax.plot(df_main['lam'], df_main['best_threshold'], 'o-', color='tab:brown')
        ax.set_title('æœ€ä¼˜é˜ˆå€¼ Î¸*'); ax.set_xlabel('Î»'); ax.set_ylabel('Î¸*'); ax.grid(alpha=0.3)

        ax = axes[2, 0]
        counts = df_main['locally_concave'].value_counts()
        ax.bar(['å‡¹', 'éå‡¹'], [counts.get(True, 0), counts.get(False, 0)],
               color=['tab:green', 'tab:red'])
        ax.set_title('å±€éƒ¨å‡¹æ€§ç»Ÿè®¡'); ax.grid(axis='y', alpha=0.3)

        ax = axes[2, 1]
        imp_mask = df_main['improvement'] > 1e-9
        ax.bar(['æœ‰æ”¹è¿›', 'æ— æ”¹è¿›'], [imp_mask.sum(), (~imp_mask).sum()], color=['teal', 'gray'])
        ax.set_title('äºŒå…ƒä¿¡å·æ˜¯å¦äº§ç”Ÿæ”¹è¿›'); ax.grid(axis='y', alpha=0.3)

        ax = axes[2, 2]
        ax.plot(df_main['lam'], df_main['K_pos_pairs'], 'o-', color='tab:purple')
        ax.set_title('è§£ææ ¸ K>0 çš„å¯¹æ•°'); ax.set_xlabel('Î»'); ax.set_ylabel('#(K>0)'); ax.grid(alpha=0.3)

        plt.suptitle('VODï¼šæ˜¾å¼æ ¸ ğ’¦ çš„å‡¹æ€§ä¸ä¿¡æ¯ä»·å€¼ï¼ˆæœ€ç»ˆç‰ˆï¼‰', fontsize=14, fontweight='bold')
        plt.tight_layout()
        png_path = os.path.join(outdir, 'summary_kernel_binary_Kfinal.png')
        plt.savefig(png_path, dpi=220, bbox_inches='tight')
        plt.close()

        # ====== å¯¼å‡º Excel ======
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        xlsx_path = os.path.join(outdir, f'results_kernel_binary_Kfinal_{ts}.xlsx')
        with pd.ExcelWriter(xlsx_path, engine='openpyxl') as writer:
            # ä¸»ç»“æœ
            df_main.to_excel(writer, sheet_name='Main', index=False)
            # æ¯ä¸ª Î» çš„é˜ˆå€¼ç»†è¡¨
            for lam in lam_values:
                thr_df = per_lambda_thr_tables[lam]
                sheet = f"thr_lambda_{lam}".replace('.', '_')
                sheet = sheet[:31]
                thr_df.to_excel(writer, sheet_name=sheet, index=False)
            # æ¯ä¸ª Î» çš„æ ¸è¡¨
            for lam in lam_values:
                ker_df = per_lambda_K_tables[lam]
                sheet = f"kernel_lambda_{lam}".replace('.', '_')
                sheet = sheet[:31]
                ker_df.to_excel(writer, sheet_name=sheet, index=False)

        print(f"\nâœ… å›¾å·²ä¿å­˜ï¼š{png_path}")
        print(f"âœ… Excel å·²ä¿å­˜ï¼š{xlsx_path}")
        return df_main, per_lambda_thr_tables, per_lambda_K_tables, png_path, xlsx_path


def main():
    analyzer = VODKernelBinaryAnalyzer(n_max=30, R=10.0, c=1.0, V=50.0)
    lam_values = np.arange(1, 21, 1.0)  # Î»=1..20
    df_main, thr_tabs, K_tabs, png, xlsx = analyzer.run(lam_values, scan_all_pairs=False)
    # æ§åˆ¶å°å°ç»“
    any_tau_issue = ((df_main['tau_L'] < -1e-12) | (df_main['tau_L'] > 1+1e-12) |
                     (df_main['tau_H'] < -1e-12) | (df_main['tau_H'] > 1+1e-12)).any()
    print("\nÏ„ æ£€æŸ¥ï¼š", "é€šè¿‡ï¼ˆå‡åœ¨ [0,1] ä¸”å’Œä¸º 1ï¼‰" if not any_tau_issue else "å‘ç°å¼‚å¸¸ï¼")
    print("æ ¸ K>0 æ˜¯å¦ä¸â€œæœ‰æ”¹è¿›â€ä¸€è‡´ï¼Ÿ",
          "æ˜¯" if (df_main['any_K_pos'] == (df_main['improvement'] > 1e-9)).all() else "å­˜åœ¨å·®å¼‚ï¼ˆè¯·æ ¸æŸ¥é˜ˆå€¼/æ•°å€¼å®¹å·®ï¼‰")
    return df_main


if __name__ == "__main__":
    _ = main()